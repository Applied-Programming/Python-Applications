{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Website Scanner\n",
    "\n",
    "The following scripts can be used to extract particular information about a particular website\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## *domain_name.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In https://www.fcbarcelona.com, fcbarcelona.com is the top level domain\n",
    "#whois can be used to get it\n",
    "#cmd: whois fcbarcelona.com\n",
    "\n",
    "from tld import get_tld\n",
    "\n",
    "def get_domain_name(url):\n",
    "    domain_name = get_tld(url)  #pass url and it gives top level domain\n",
    "    return domain_name\n",
    "\n",
    "#print(get_domain_name(\"https://www.fcbarcelona.com\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *ip_address.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in linux\n",
    "#command host fcbarcelona.com gets the ip address\n",
    "#host fcbarcelona.com\n",
    "#fcbarcelona.com has address 54.186.250.79\n",
    "\n",
    "#in windows\n",
    "#command ping fcbarcelona.com gets the ip address\n",
    "#host fcbarcelona.com\n",
    "#fcbarcelona.com has address 54.186.250.79\n",
    "\n",
    "import os\n",
    "\n",
    "def get_ip_address(url):\n",
    "\n",
    "    # for linux\n",
    "    # command = \"host \" + url\n",
    "    # process = os.popen(command)  #runs a new process/ opens the terminal to get the ip address\n",
    "    # results = str(process.read())  #get the string value of ip address\n",
    "    # marker = results.find('has address') + 12  #get to the end of the has address\n",
    "    # #return results[marker:].splitlines()[0]  #splitlines()[0] returns the top line with the 1st ip address of the site that has multiple ip addresses\n",
    "    # return results[marker:]\n",
    "\n",
    "    #for windows\n",
    "    command = \"ping \" + url\n",
    "    process = os.popen(command)  #runs a new process/ opens the cmd to get the ip address\n",
    "    results = str(process.read())  #get the string value of ip address\n",
    "    strurl = str(url)\n",
    "    marker = results.find('Pinging ' + url) + 8 + len(strurl) + 2  #get to the end of the Pinging url\n",
    "    marker2 = results.find('with')-2\n",
    "\n",
    "    return results[marker:marker2].splitlines()[0]  #splitlines()[0] returns the top line with the 1st ip address of the site that has multiple ip addresses\n",
    "\n",
    "\n",
    "print(get_ip_address('fcbarcelona.com'))\n",
    "#print(get_ip_address('google.com'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *nmap.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_namp(options, ip):\n",
    "    command = \"nmap \" + options + \" \" + ip\n",
    "    process = os.popen(command)\n",
    "    results = str(process.read())\n",
    "    return results\n",
    "\n",
    "#print(get_namp('-F','Here-enter-the-ip-address-of-the-website-you-are-scanning'))\n",
    "print(get_namp('-F','176.34.188.253'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *robots_txt.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import io\n",
    "\n",
    "def get_robots_txt(url):\n",
    "    if url.endswith('/'):\n",
    "        path = url\n",
    "    else:\n",
    "        path = url + '/'\n",
    "    req = urllib.request.urlopen(path + \"robots.txt\", data=None)\n",
    "    data = io.TextIOWrapper(req, encoding='utf-8')\n",
    "    return data.read()\n",
    "\n",
    "#print(get_robots_txt('https://www.google.com/'))\n",
    "print(get_robots_txt('https://fcbarcelona.com'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *whois.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_whois(url):\n",
    "    command = \"whois \" + url\n",
    "    process = os.popen(command)\n",
    "    results = str(process.read())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *general.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_dir(directory): #check if the directory already exists, if not cretae a new one to store info files\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def write_file(path,data): #write the file\n",
    "    f = open(path,'w')\n",
    "    f.write(data)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *main.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from general import *\n",
    "from domain_name import *\n",
    "from ip_address import *\n",
    "from nmap import *\n",
    "from robots.txt import *\n",
    "from whois import *\n",
    "\n",
    "ROOT_DIR = 'companies'\n",
    "create_dir(ROOT_DIR)\n",
    "\n",
    "def gather_info(name,url):\n",
    "    domain_name = get_domain_name(url)\n",
    "    ip_address = get_ip_address(url)\n",
    "    nmap = get_nmap('-F', 'ip_address')\n",
    "    robots_txt= get_robots_txt(url)\n",
    "    whois= get_whois(domain_name)\n",
    "    create_report(name, url, domain_name, nmap, robots_txt, whois)\n",
    "\n",
    "def create_report(name, url, domain_name, nmap, robots_txt, whois):\n",
    "    project_dir = ROOT_DIR + '/' + name\n",
    "    create_dir(project_dir)\n",
    "    write_file(project_dir + '/full_url.txt' , full_url)\n",
    "    write_file(project_dir + '/domain_name.txt' , domain_name)\n",
    "    write_file(project_dir + '/nmap.txt' , nmap)\n",
    "    write_file(project_dir + '/robots_txt.txt' , robots_txt)\n",
    "    write_file(project_dir + '/whois.txt' , whois)\n",
    "\n",
    "\n",
    "gather_info('fcbarcelona.com', 'https://fcbarcelona.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `main.py` to start scanning the websites.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
